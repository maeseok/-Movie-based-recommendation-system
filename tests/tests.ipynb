{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install torch_geometric"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. 데이터 로드 및 준비"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.data import Data, DataLoader\n",
    "from torch_geometric.utils import to_undirected\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# 데이터 로드 및 스케일링\n",
    "book_embeddings = pd.read_csv('/kaggle/input/bookembedding/Book_Embedding_KoBERT.csv').values\n",
    "movie_embeddings = pd.read_csv('/kaggle/input/movieembedding/Movie_Embedding_KoBERT.csv').values\n",
    "book_data = pd.read_excel('/kaggle/input/book-data/Books_Data.xlsx')\n",
    "movie_data = pd.read_csv('/kaggle/input/moviedata/KoBERT_movie_keyword.csv')\n",
    "\n",
    "scaler = StandardScaler()\n",
    "book_embeddings = scaler.fit_transform(book_embeddings)\n",
    "movie_embeddings = scaler.fit_transform(movie_embeddings)\n",
    "\n",
    "# 텐서로 변환 및 평점 정규화\n",
    "book_embeddings = torch.tensor(book_embeddings, dtype=torch.float32)\n",
    "movie_embeddings = torch.tensor(movie_embeddings, dtype=torch.float32)\n",
    "book_ratings = torch.tensor(book_data['평점'].values, dtype=torch.float32)\n",
    "movie_ratings = torch.tensor(movie_data['평점'].values, dtype=torch.float32)\n",
    "\n",
    "# 평점 정규화 및 임베딩 결합\n",
    "rating_weight = 2\n",
    "book_features = torch.cat([book_embeddings, book_ratings.unsqueeze(1) * rating_weight], dim=1)\n",
    "movie_features = torch.cat([movie_embeddings, movie_ratings.unsqueeze(1) * rating_weight], dim=1)\n",
    "\n",
    "# 트레인/테스트 데이터셋 분할 및 차원 맞추기\n",
    "train_movie_features, _, train_movie_ratings, _ = train_test_split(\n",
    "    movie_features, movie_ratings, test_size=0.2, random_state=42\n",
    ")\n",
    "train_book_features, _, train_book_ratings, _ = train_test_split(\n",
    "    book_features, book_ratings, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "max_dim = max(train_movie_features.size(1), train_book_features.size(1))\n",
    "if train_movie_features.size(1) < max_dim:\n",
    "    padding_size = max_dim - train_movie_features.size(1)\n",
    "    train_movie_features = torch.cat([train_movie_features, torch.zeros(train_movie_features.size(0), padding_size)], dim=1)\n",
    "if train_book_features.size(1) < max_dim:\n",
    "    padding_size = max_dim - train_book_features.size(1)\n",
    "    train_book_features = torch.cat([train_book_features, torch.zeros(train_book_features.size(0), padding_size)], dim=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. 그래프 데이터 구성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.utils import to_undirected\n",
    "\n",
    "# 임베딩과 평점 결합 함수\n",
    "def combine_embeddings_with_ratings(embeddings, ratings, rating_weight=2.0):\n",
    "    ratings = ratings.unsqueeze(1) * rating_weight\n",
    "    return torch.cat([embeddings, ratings], dim=1)\n",
    "\n",
    "# 배치 처리 기반의 개선된 엣지 생성 함수 (메모리 최적화)\n",
    "def create_edges_in_batches(movie_features, book_features, top_k=5, batch_size=1024):\n",
    "    edge_index = []\n",
    "    num_movies = movie_features.size(0)\n",
    "    num_books = book_features.size(0)\n",
    "    \n",
    "    for start_idx in range(0, num_movies, batch_size):\n",
    "        end_idx = min(start_idx + batch_size, num_movies)\n",
    "        movie_batch = movie_features[start_idx:end_idx]\n",
    "\n",
    "        # 코사인 유사도 계산 (배치별)\n",
    "        cos_sim = F.cosine_similarity(movie_batch.unsqueeze(1), book_features.unsqueeze(0), dim=-1)\n",
    "\n",
    "        # 각 영화에 대해 상위 k개의 도서만 선택\n",
    "        for movie_idx in range(cos_sim.size(0)):\n",
    "            top_k_books = cos_sim[movie_idx].topk(top_k, largest=True).indices\n",
    "            for book_idx in top_k_books:\n",
    "                edge_index.append([start_idx + movie_idx, book_idx.item() + num_movies])\n",
    "    \n",
    "    edge_index = torch.tensor(edge_index, dtype=torch.long).t().contiguous()\n",
    "    edge_index = to_undirected(edge_index)\n",
    "    \n",
    "    return edge_index\n",
    "\n",
    "# 임베딩과 평점 결합\n",
    "train_movie_combined = combine_embeddings_with_ratings(train_movie_features, train_movie_ratings, rating_weight)\n",
    "train_book_combined = combine_embeddings_with_ratings(train_book_features, train_book_ratings, rating_weight)\n",
    "\n",
    "# 배치 처리 기반의 엣지 생성\n",
    "combined_edge_index = create_edges_in_batches(train_movie_combined, train_book_combined, top_k=3, batch_size=1024)\n",
    "\n",
    "# 그래프 데이터 구성\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "x_train = torch.cat([train_movie_combined, train_book_combined], dim=0).to(device)\n",
    "combined_edge_index = combined_edge_index.to(device)\n",
    "\n",
    "# Data 객체 생성\n",
    "data_train = Data(x=x_train, edge_index=combined_edge_index)\n",
    "\n",
    "# 데이터 확인\n",
    "print(data_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. 모델 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GATConv\n",
    "from torch_geometric.data import Data\n",
    "\n",
    "# GATNet 모델 정의\n",
    "class GATNet(torch.nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim, heads=8, dropout=0.2):\n",
    "        super(GATNet, self).__init__()\n",
    "        self.gat1 = GATConv(input_dim, hidden_dim, heads=heads, concat=True, dropout=dropout)\n",
    "        self.gat2 = GATConv(hidden_dim * heads, output_dim, heads=1, concat=False, dropout=dropout)\n",
    "        self.dropout = torch.nn.Dropout(dropout)\n",
    "        self.batch_norm1 = torch.nn.BatchNorm1d(hidden_dim * heads)  # 배치 정규화 추가\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        x = self.gat1(x, edge_index)\n",
    "        x = self.batch_norm1(x)  # 배치 정규화\n",
    "        x = F.elu(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.gat2(x, edge_index)\n",
    "        return x\n",
    "\n",
    "# 모델 및 옵티마이저 초기화\n",
    "input_dim = x_train.size(1)\n",
    "hidden_dim = 128  # 히든 차원 확장\n",
    "output_dim = input_dim\n",
    "\n",
    "model = GATNet(input_dim, hidden_dim, output_dim, heads=8, dropout=0.3).to(device)  # 드롭아웃 증가\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001, weight_decay=5e-4)  # 학습률 감소, weight_decay 증가\n",
    "criterion = torch.nn.MSELoss()\n",
    "\n",
    "# 학습 루프\n",
    "model.train()\n",
    "for epoch in range(1, 5001):  # 에포크 수를 줄이고 조기 종료 조건 추가 가능\n",
    "    optimizer.zero_grad()\n",
    "    out = model(data_train.x, data_train.edge_index)\n",
    "    loss = criterion(out, data_train.x)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    if epoch % 100 == 0:\n",
    "        print(f'Epoch {epoch}, Loss: {loss.item():.4f}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. 모델 평가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# 데이터 분할 시 데이터프레임과 임베딩을 함께 분할\n",
    "movie_data_train, movie_data_test, train_movie_features, test_movie_features = train_test_split(\n",
    "    movie_data, movie_features, test_size=0.2, random_state=42)\n",
    "\n",
    "book_data_train, book_data_test, train_book_features, test_book_features = train_test_split(\n",
    "    book_data, book_features, test_size=0.2, random_state=42)\n",
    "\n",
    "# 영화와 도서 데이터셋이 있는지 확인 (수정 후)\n",
    "assert len(movie_data_train) == len(train_movie_features), \"영화 데이터의 길이와 학습 영화 임베딩의 길이가 다릅니다.\"\n",
    "assert len(book_data_train) == len(train_book_features), \"도서 데이터의 길이와 학습 도서 임베딩의 길이가 다릅니다.\"\n",
    "\n",
    "# 추천 시스템 함수 (영화에 대해 도서 추천)\n",
    "def recommend_book_for_movie(model, movie_embeddings, all_book_embeddings, top_k=1):\n",
    "    model.eval()\n",
    "    recommended_books = []\n",
    "    with torch.no_grad():\n",
    "        # 각 영화에 대해 유사한 도서 추천\n",
    "        for movie_embedding in movie_embeddings:\n",
    "            movie_embedding = movie_embedding.to(device).unsqueeze(0)  # 배치 차원 추가\n",
    "            book_embeddings = all_book_embeddings.to(device)\n",
    "            \n",
    "            \n",
    "            distances = torch.cdist(movie_embedding, book_embeddings, p=10)  \n",
    "            top_k_indices = distances.topk(top_k, largest=False).indices\n",
    "            recommended_books.append([idx.item() for idx in top_k_indices.squeeze()])\n",
    "    \n",
    "    return recommended_books\n",
    "\n",
    "# 모델에 사용할 임베딩들만 선택하여 추천 수행\n",
    "recommended_books_indices = recommend_book_for_movie(model, train_movie_features, train_book_features, top_k=3)\n",
    "\n",
    "# 영화 및 도서 제목 가져오기\n",
    "movie_titles = movie_data_train['제목'].tolist()  # 학습 데이터의 영화 제목 리스트\n",
    "book_titles = book_data_train['도서명'].tolist()  # 학습 데이터의 도서 제목 리스트\n",
    "\n",
    "# 추천 도서의 제목 리스트 생성\n",
    "recommended_books = [[book_titles[idx] for idx in indices] for indices in recommended_books_indices]\n",
    "\n",
    "# 결과를 DataFrame으로 저장\n",
    "result_df = pd.DataFrame({\n",
    "    '영화 제목': movie_titles[:len(recommended_books_indices)],\n",
    "    '추천 도서': [' / '.join(book_titles[idx] for idx in indices) for indices in recommended_books_indices]\n",
    "})\n",
    "\n",
    "# 결과를 xlsx 파일로 저장\n",
    "output_path = '영화_도서_추천_결과.xlsx'\n",
    "result_df.to_excel(output_path, index=False)\n",
    "\n",
    "print(f\"Recommendation results saved to {output_path}\")\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
